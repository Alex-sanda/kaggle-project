{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup \n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as TFIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./dataset/labeledTrainData.tsv', header=0,\n",
    "                delimiter=\"\\t\", quoting=3)\n",
    "test = pd.read_csv('./dataset/testData.tsv', header=0, delimiter=\"\\t\",\n",
    "               quoting=3 )\n",
    "               \n",
    "# Import both the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#文本清理函数，生成wordlist\n",
    "def review_to_wordlist(review):\n",
    "    '''\n",
    "    Meant for converting each of the IMDB reviews into a list of words.\n",
    "    '''\n",
    "    # First remove the HTML.\n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "    \n",
    "    # Use regular expressions to only include words.\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    \n",
    "    # Convert words to lower case and split them into separate words.\n",
    "    words = review_text.lower().split()\n",
    "   \n",
    "    # Return a list of words\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#label\n",
    "y_train = train['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /home/alex/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "#处理成TF-IDF需要的数据格式[num_sample,],每个sample都是一段string文本\n",
    "traindata = []\n",
    "for i in range(0,len(train['review'])):\n",
    "    traindata.append(\" \".join(review_to_wordlist(train['review'][i])))\n",
    "testdata = []\n",
    "for i in range(0,len(test['review'])):\n",
    "    testdata.append(\" \".join(review_to_wordlist(test['review'][i])))\n",
    "\n",
    "#调用sklearn的文本特征提取器\n",
    "tfv = TFIV(min_df=3,  max_features=None, \n",
    "        strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "        ngram_range=(1, 2), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "        stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_all = traindata + testdata # Combine both to fit the TFIDF vectorization.\n",
    "lentrain = len(traindata)\n",
    "\n",
    "tfv.fit(X_all) # This is the slow part!\n",
    "X_all = tfv.transform(X_all)\n",
    "\n",
    "X = X_all[:lentrain] # Separate back into training and test sets. \n",
    "X_test = X_all[lentrain:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建分类器：\n",
    "LR/朴素贝叶斯/SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/alex/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=20, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1, param_grid={'C': [30]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_values = {'C':[30]} # Decide which settings you want for the grid search. \n",
    "\n",
    "model_LR = GridSearchCV(LR(penalty = 'l2', dual = True, random_state = 0), \n",
    "                        grid_values, scoring = 'roc_auc', cv = 20) \n",
    "# Try to set the scoring on what the contest is asking for. \n",
    "# The contest says scoring is for area under the ROC curve, so use this.\n",
    "                        \n",
    "model_LR.fit(X,y_train) # Fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB as MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_NB = MNB()\n",
    "model_NB.fit(X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 Fold CV Score for Multinomial Naive Bayes:  0.94963712\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "print(\"20 Fold CV Score for Multinomial Naive Bayes: \", np.mean(cross_val_score\n",
    "                                                                (model_NB, X, y_train, cv=20, scoring='roc_auc')))\n",
    "     # This will give us a 20-fold cross validation score that looks at ROC_AUC so we can compare with Logi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=20, error_score='raise',\n",
       "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='modified_huber', max_iter=5,\n",
       "       n_iter=None, n_jobs=1, penalty='l2', power_t=0.5, random_state=0,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': [6e-05, 7e-05, 8e-05, 0.0001, 0.0005]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier as SGD\n",
    "sgd_params = {'alpha': [0.00006, 0.00007, 0.00008, 0.0001, 0.0005]} # Regularization parameter\n",
    "\n",
    "model_SGD = GridSearchCV(SGD(random_state = 0, shuffle = True, loss = 'modified_huber'), \n",
    "                        sgd_params, scoring = 'roc_auc', cv = 20) # Find out which regularization parameter works the best. \n",
    "                        \n",
    "model_SGD.fit(X, y_train) # Fit the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#输出LR分类结果\n",
    "LR_result = model_LR.predict(X_test)\n",
    "LR_out = pd.DataFrame(data={\"id\":test[\"id\"],\"sentiment\":LR_result})\n",
    "LR_out.to_csv(\"Logistic_Reg.csv\",index=False,quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#输出朴素贝叶斯分类结果\n",
    "NB_result = model_NB.predict(X_test)\n",
    "NB_out = pd.DataFrame(data={\"id\":test[\"id\"],\"sentiment\":NB_result})\n",
    "NB_out.to_csv(\"MNB.csv\",index=False,quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#输出SGD模型输出\n",
    "SGD_result = model_SGD.predict(X_test)\n",
    "NB_out = pd.DataFrame(data={\"id\":test[\"id\"],\"sentiment\":SGD_result})\n",
    "NB_out.to_csv(\"SGD.csv\",index=False,quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
