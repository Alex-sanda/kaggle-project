{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re #正则biaodas\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#用pandas读入数据\n",
    "train = pd.read_csv(\"./dataset/labeledTrainData.tsv\",\n",
    "                    header=0,\n",
    "                    delimiter='\\t',\n",
    "                    quoting=3)\n",
    "test = pd.read_csv(\"./dataset/testData.tsv\",\n",
    "                    header=0,\n",
    "                    delimiter='\\t',\n",
    "                    quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_to_wordlist(review,remove_stopwords=False):\n",
    "    \"\"\"\n",
    "function to make review into wordlist:\n",
    "1.去网页标签\n",
    "2.去掉数字\n",
    "3.以空格为分隔符分割句子\n",
    "4.option：如果发现有字符在停用字符中，删除掉\n",
    "\"\"\"\n",
    "    #1.去网页标签\n",
    "    cleaned_review = BeautifulSoup(review).get_text()\n",
    "    #2.去掉数字\n",
    "    cleaned_review = re.sub(\"[^a-zA-Z]\",\" \",cleaned_review)\n",
    "    #3.split review into wordlist\n",
    "    words = cleaned_review.lower().split()\n",
    "    #4.stop_words if ask\n",
    "    if remove_stopwords:\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        words = [word for word in words if word not in stop_words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /home/alex/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['stuff',\n",
       " 'going',\n",
       " 'moment',\n",
       " 'mj',\n",
       " 'started',\n",
       " 'listening',\n",
       " 'music',\n",
       " 'watching',\n",
       " 'odd',\n",
       " 'documentary',\n",
       " 'watched',\n",
       " 'wiz',\n",
       " 'watched',\n",
       " 'moonwalker',\n",
       " 'maybe',\n",
       " 'want',\n",
       " 'get',\n",
       " 'certain',\n",
       " 'insight',\n",
       " 'guy',\n",
       " 'thought',\n",
       " 'really',\n",
       " 'cool',\n",
       " 'eighties',\n",
       " 'maybe',\n",
       " 'make',\n",
       " 'mind',\n",
       " 'whether',\n",
       " 'guilty',\n",
       " 'innocent',\n",
       " 'moonwalker',\n",
       " 'part',\n",
       " 'biography',\n",
       " 'part',\n",
       " 'feature',\n",
       " 'film',\n",
       " 'remember',\n",
       " 'going',\n",
       " 'see',\n",
       " 'cinema',\n",
       " 'originally',\n",
       " 'released',\n",
       " 'subtle',\n",
       " 'messages',\n",
       " 'mj',\n",
       " 'feeling',\n",
       " 'towards',\n",
       " 'press',\n",
       " 'also',\n",
       " 'obvious',\n",
       " 'message',\n",
       " 'drugs',\n",
       " 'bad',\n",
       " 'kay',\n",
       " 'visually',\n",
       " 'impressive',\n",
       " 'course',\n",
       " 'michael',\n",
       " 'jackson',\n",
       " 'unless',\n",
       " 'remotely',\n",
       " 'like',\n",
       " 'mj',\n",
       " 'anyway',\n",
       " 'going',\n",
       " 'hate',\n",
       " 'find',\n",
       " 'boring',\n",
       " 'may',\n",
       " 'call',\n",
       " 'mj',\n",
       " 'egotist',\n",
       " 'consenting',\n",
       " 'making',\n",
       " 'movie',\n",
       " 'mj',\n",
       " 'fans',\n",
       " 'would',\n",
       " 'say',\n",
       " 'made',\n",
       " 'fans',\n",
       " 'true',\n",
       " 'really',\n",
       " 'nice',\n",
       " 'actual',\n",
       " 'feature',\n",
       " 'film',\n",
       " 'bit',\n",
       " 'finally',\n",
       " 'starts',\n",
       " 'minutes',\n",
       " 'excluding',\n",
       " 'smooth',\n",
       " 'criminal',\n",
       " 'sequence',\n",
       " 'joe',\n",
       " 'pesci',\n",
       " 'convincing',\n",
       " 'psychopathic',\n",
       " 'powerful',\n",
       " 'drug',\n",
       " 'lord',\n",
       " 'wants',\n",
       " 'mj',\n",
       " 'dead',\n",
       " 'bad',\n",
       " 'beyond',\n",
       " 'mj',\n",
       " 'overheard',\n",
       " 'plans',\n",
       " 'nah',\n",
       " 'joe',\n",
       " 'pesci',\n",
       " 'character',\n",
       " 'ranted',\n",
       " 'wanted',\n",
       " 'people',\n",
       " 'know',\n",
       " 'supplying',\n",
       " 'drugs',\n",
       " 'etc',\n",
       " 'dunno',\n",
       " 'maybe',\n",
       " 'hates',\n",
       " 'mj',\n",
       " 'music',\n",
       " 'lots',\n",
       " 'cool',\n",
       " 'things',\n",
       " 'like',\n",
       " 'mj',\n",
       " 'turning',\n",
       " 'car',\n",
       " 'robot',\n",
       " 'whole',\n",
       " 'speed',\n",
       " 'demon',\n",
       " 'sequence',\n",
       " 'also',\n",
       " 'director',\n",
       " 'must',\n",
       " 'patience',\n",
       " 'saint',\n",
       " 'came',\n",
       " 'filming',\n",
       " 'kiddy',\n",
       " 'bad',\n",
       " 'sequence',\n",
       " 'usually',\n",
       " 'directors',\n",
       " 'hate',\n",
       " 'working',\n",
       " 'one',\n",
       " 'kid',\n",
       " 'let',\n",
       " 'alone',\n",
       " 'whole',\n",
       " 'bunch',\n",
       " 'performing',\n",
       " 'complex',\n",
       " 'dance',\n",
       " 'scene',\n",
       " 'bottom',\n",
       " 'line',\n",
       " 'movie',\n",
       " 'people',\n",
       " 'like',\n",
       " 'mj',\n",
       " 'one',\n",
       " 'level',\n",
       " 'another',\n",
       " 'think',\n",
       " 'people',\n",
       " 'stay',\n",
       " 'away',\n",
       " 'try',\n",
       " 'give',\n",
       " 'wholesome',\n",
       " 'message',\n",
       " 'ironically',\n",
       " 'mj',\n",
       " 'bestest',\n",
       " 'buddy',\n",
       " 'movie',\n",
       " 'girl',\n",
       " 'michael',\n",
       " 'jackson',\n",
       " 'truly',\n",
       " 'one',\n",
       " 'talented',\n",
       " 'people',\n",
       " 'ever',\n",
       " 'grace',\n",
       " 'planet',\n",
       " 'guilty',\n",
       " 'well',\n",
       " 'attention',\n",
       " 'gave',\n",
       " 'subject',\n",
       " 'hmmm',\n",
       " 'well',\n",
       " 'know',\n",
       " 'people',\n",
       " 'different',\n",
       " 'behind',\n",
       " 'closed',\n",
       " 'doors',\n",
       " 'know',\n",
       " 'fact',\n",
       " 'either',\n",
       " 'extremely',\n",
       " 'nice',\n",
       " 'stupid',\n",
       " 'guy',\n",
       " 'one',\n",
       " 'sickest',\n",
       " 'liars',\n",
       " 'hope',\n",
       " 'latter']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_to_wordlist(train[\"review\"][0],remove_stopwords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /home/alex/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train review :5000 / 25000\n",
      "train review :10000 / 25000\n",
      "train review :15000 / 25000\n",
      "train review :20000 / 25000\n",
      "train review :25000 / 25000\n",
      "Done with train : reviews to word list\n",
      "test review :5000 / 25000\n",
      "test review :10000 / 25000\n",
      "test review :15000 / 25000\n",
      "test review :20000 / 25000\n",
      "test review :25000 / 25000\n",
      "Done with test : reviews to word list\n"
     ]
    }
   ],
   "source": [
    "#将train/test中的review转换成wordlist\n",
    "train_data = []\n",
    "for i in range(len(train[\"review\"])):\n",
    "    if (i+1)%5000 == 0:\n",
    "        print(\"train review :{} / {}\".format(i+1,len(train[\"review\"])))\n",
    "    train_data.append(\" \".join(review_to_wordlist(train[\"review\"][i])))\n",
    "print(\"Done with train : reviews to word list\")\n",
    "\n",
    "test_data = []\n",
    "for i in range(len(test[\"review\"])):\n",
    "    if (i+1)%5000 == 0:\n",
    "        print(\"test review :{} / {}\".format(i+1,len(test[\"review\"])))\n",
    "    train_data.append(\" \".join(review_to_wordlist(test[\"review\"][i])))\n",
    "print(\"Done with test : reviews to word list\")\n",
    "\n",
    "#training label y\n",
    "y_train = train[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use TF-IDF to generate features \n",
    "\n",
    "-About TF-IDF : https://blog.csdn.net/zrc199021/article/details/53728499"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer as TFIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#初始化TF-IDF对象，去停用词。加二元语言模型\n",
    "tfv = TFIV(min_df=3,\n",
    "           max_features=None,\n",
    "           strip_accents='unicode',\n",
    "           analyzer='word',\n",
    "           token_pattern=r'\\w{1,}',\n",
    "           ngram_range=(1, 2),\n",
    "           use_idf=1,smooth_idf=1,\n",
    "           sublinear_tf=1,\n",
    "           stop_words = 'english')\n",
    "\n",
    "#生成tf-idf feature\n",
    "All_reviews = train_data+test_data\n",
    "tfv.fit(All_reviews)\n",
    "All_review_tfidf = tfv.transform(All_reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_tfidf = All_review_tfidf[:len(train[\"review\"])]\n",
    "test_tfidf = All_review_tfidf[len(train[\"review\"]):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "多项式贝叶斯分类器20折交叉验证得分:  0.94963712\n"
     ]
    }
   ],
   "source": [
    "#构建朴素贝叶斯分类器\n",
    "from sklearn.naive_bayes import MultinomialNB as MNB\n",
    "\n",
    "model_NB = MNB()\n",
    "model_NB.fit(train_tfidf, y_train) #特征数据直接灌进来\n",
    "MNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import numpy as np\n",
    "print (\"多项式贝叶斯分类器20折交叉验证得分: \", np.mean(cross_val_score(model_NB, train_tfidf, y_train, cv=20, scoring='roc_auc')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
